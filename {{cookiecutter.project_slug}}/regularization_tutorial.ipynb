{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Tutorial\n",
    "\n",
    "Welcome to the ART regularization tutorial. At this point we assume that you are quite confident about your model and now your goal is to achieve reasonable accuracy. We will start from the `Overfit` stage. If you are not familiar with ART consider checking other [tutorials](https://github.com/SebChw/Actually-Robust-Training#tutorials).\n",
    "\n",
    "\n",
    "We wrote `dataset.py`, `modifiers.py` and `models.base_model.py` for you. If you are interested please check them out! Everything is described inside them.\n",
    "\n",
    "Let's start from the project definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed for reproducibility\n",
    "from lightning import seed_everything\n",
    "seed_everything(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from dataset import FruitsDataModule, N_CLASSES\n",
    "from models.base_model import FoodClassifier\n",
    "from torchmetrics import Accuracy\n",
    "from art.project import ArtProject\n",
    "\n",
    "data_module = FruitsDataModule() # Datamodule on which we try to achieve good performance\n",
    "model = FoodClassifier # Model class with which we want to achieve it\n",
    "project = ArtProject(\"regularize\", data_module) # Create a project with a name and a datamodule\n",
    "#Register metrics to be tracked\n",
    "loss, accuracy = nn.CrossEntropyLoss(), Accuracy(task=\"multiclass\", num_classes=N_CLASSES)\n",
    "project.register_metrics([loss, accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we define a Model Callback that will save models with best validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from art.metrics import build_metric_name\n",
    "from art.utils.enums import TrainingStage\n",
    "\n",
    "checkpoint = ModelCheckpoint(monitor=build_metric_name(accuracy, TrainingStage.VALIDATION.value), mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can observe quite important philosophy of ART we try to omit MAGIC values everything is defined programmaticaly.\n",
    "\n",
    "Next, lets define a check to validate our regularization progress. Our client will be satisfied with 75% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.checks import CheckScoreGreaterThan\n",
    "\n",
    "WANTED_SCORE = 0.75\n",
    "acc_check = CheckScoreGreaterThan(accuracy, WANTED_SCORE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly Lets assume that we will be always doing 10 epochs of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_KWARGS = {\"callbacks\": [checkpoint], \"max_epochs\": 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from no regularization. Maybe it's not needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.steps import Regularize\n",
    "\n",
    "project.add_step(Regularize(model), checks = [acc_check])\n",
    "project.run_all(trainer_kwargs=TRAINER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatelly it is needed. Generally we should try to introduce regularizations from these that are most certain to improve out score:\n",
    "\n",
    "1. Get more training data -  hard, although it's the only guaranteed way to monotonically improve the performance of a well-configured neural network almost indefinitely.\n",
    "2. Data augmentations\n",
    "3. Generating fake data\n",
    "4. Pretraining\n",
    "5. Decreasing the network complexity\n",
    "6. Decreasing the batch size, weight decay, dropout etc.\n",
    "7. Early Stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modifiers import AddMoreDataModifier\n",
    "\n",
    "project.add_step(Regularize(model, datamodule_modifiers=[AddMoreDataModifier()]), checks = [acc_check])\n",
    "project.run_all(trainer_kwargs=TRAINER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the previous Regularize step was not executed again.\n",
    "\n",
    "So the ART idea for regularization is to achieved by `modifiers`. These are functions that modify something in the model or dataloader to achieve different trainings. By utilizing modifiers we can track them with `git`. Moreover we are not expanding our model and data classes.\n",
    "\n",
    "As you can see adding more data as always helps. But we are still not there.\n",
    "\n",
    "Now we add 2 runs: one with little and second with many augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modifiers import SetLittleTransformsModifier, SetManyTransformsModifier\n",
    "\n",
    "project.add_step(Regularize(model, datamodule_modifiers=[AddMoreDataModifier()],\n",
    "                            model_modifiers=[SetLittleTransformsModifier()]), checks = [acc_check])\n",
    "project.add_step(Regularize(model, datamodule_modifiers=[AddMoreDataModifier()],\n",
    "                            model_modifiers=[SetManyTransformsModifier()]), checks = [acc_check])\n",
    "\n",
    "project.run_all(trainer_kwargs=TRAINER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually there is a third option - we can just pass kwargs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.add_step(Regularize(model, datamodule_modifiers=[AddMoreDataModifier()],\n",
    "                            model_modifiers=[SetManyTransformsModifier()], \n",
    "                            model_kwargs={\"weight_decay\": 0.5}), checks = [acc_check])\n",
    "\n",
    "project.run_all(trainer_kwargs=TRAINER_KWARGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see when we suceeded with regularization next trials won't be run.\n",
    "\n",
    "Finally, you can now visualize and explore all runs using art-dashboard - `python -m art.cli run-dashboard`\n",
    "\n",
    "To guide you step by step we were introducing new regularization concept one by one and use jupyter notebook. However, you can easily write exactly the same code using script. Check `run.py` for this purpose."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

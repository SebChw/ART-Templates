{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using ART\n",
    "\n",
    "Hi! In this tutorial we will walk you through the process of using ART to perform transfer learning. We will use the [Yelp Reviews](https://huggingface.co/datasets/yelp_review_full) dataset and `bert-base-cased` model from HuggingFace. We will train a classifier to predict the sentiment of a review (positive or negative) and then we will use ART to perform transfer learning to attack the classifier. Most of the code will follow [HF's tutorial](https://huggingface.co/docs/transformers/training) with some modifications to make it work with ART.\n",
    "\n",
    "We'll do everything in a script, your task will be to fill the `run.py` accordingly with our instructions from this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install art nltk wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we need to download the data and do some analysis on it. We'll use the `datasets` library from HuggingFace to do this, and we'll wrap the model to Lightning's `DataModule` to make it easier to use with PyTorch Lightning. We prapared the dataset for you in `dataset.py`, check it out there. The main function in `run.py` is just rady to download the data and show you a sample from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can become one with the data. We want to know some statistics, that will be helpful. We prepared for you a data analisys step in `steps.py`. \n",
    "Now it's your turn! Fill the `steps.py` `...` places\n",
    "\n",
    "As you've done it, modify the main() function as follows:\n",
    "* read the data\n",
    "* start the ART project\n",
    "* add our data analisys step with checking, whether the result exists\n",
    "* run all the steps (for now we have just one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Correct TextDataAnalisys</summary>\n",
    "\n",
    "```python\n",
    "    def do(self, previous_states):\n",
    "        targets = []\n",
    "        texts = []\n",
    "\n",
    "        # Loop through batches in the YelpReviews datamodule train dataloader\n",
    "        for batch in self.datamodule.train_dataloader():\n",
    "            # Assuming 'labels' contains the review scores\n",
    "            targets.extend(batch['label'])\n",
    "            # Assuming 'text' contains the review text\n",
    "            texts.extend(batch['text'])\n",
    "\n",
    "        # Calculate the number of unique classes (review scores) in the targets\n",
    "        number_of_classes = len(np.unique(targets))\n",
    "\n",
    "        # Now tell me what the scores are\n",
    "        class_names = [str(i) for i in sorted(np.unique(targets))]\n",
    "\n",
    "        # Create a dictionary of class names and their counts\n",
    "        targets_ints = [int(i) for i in targets]\n",
    "        class_counts = Counter(targets_ints)\n",
    "\n",
    "        # count number of unique words\n",
    "        unique_words = set()\n",
    "        for text in texts:\n",
    "            unique_words.update(text.split())\n",
    "        number_of_unique_words = len(unique_words)\n",
    "\n",
    "        # Create a word cloud\n",
    "        wordcloud = WordCloud().generate(' '.join(texts))\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        MatplotLibSaver().save(\n",
    "            fig, self.get_step_id(), self.name, \"wordcloud\"\n",
    "        )\n",
    "\n",
    "        self.results.update(\n",
    "            {\n",
    "                \"number_of_classes\": number_of_classes,\n",
    "                \"class_names\": class_names,\n",
    "                \"number_of_reviews_in_each_class\": class_counts,\n",
    "            }\n",
    "        )\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Correct main()</summary>\n",
    "\n",
    "```py\n",
    "def main():\n",
    "    data = YelpReviews()\n",
    "    project = ArtProject(\"yelpreviews\", data)\n",
    "    project.add_step(TextDataAnalysis(), [\n",
    "                     CheckResultExists(\"number_of_classes\"),\n",
    "                     CheckResultExists(\"class_names\"),\n",
    "                     CheckResultExists(\"number_of_reviews_in_each_class\")])\n",
    "    project.run_all()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can see the output below, and the wordcloud.png in checkpoints folder we're good!\n",
    "```\n",
    "Steps status:\n",
    "data_analysis_Data analysis: Completed. Results:\n",
    "        number_of_classes: 5\n",
    "        class_names: ['0', '1', '2', '3', '4']\n",
    "        number_of_reviews_in_each_class: Counter({1: 240, 2: 208, 4: 189, 0: 189, 3: 174})```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the data, now we ca work on our models, that will solve sentiment analisys problem! We start with a simple baseline. But before that, we need to define metrix that we'll use throughout the entire experiment. To do it add following line after adding the DataAnalisys step:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy, Precision, Recall, F1\n",
    "\n",
    "NUM_CLASSES = project.get_step(0).get_latest_run()[\"number_of_classes\"] #get calculated number of classes in the previous step\n",
    "METRICS = [Accuracy(num_classes=NUM_CLASSES), Precision(num_classes=NUM_CLASSES), Recall(num_classes=NUM_CLASSES), F1(num_classes=NUM_CLASSES)] #define metrics\n",
    "project.register_metrics(METRICS) #register metrics in the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Correct main()</summary>\n",
    "\n",
    "```py\n",
    "def main():\n",
    "    data = YelpReviews()\n",
    "    project = ArtProject(\"yelpreviews\", data)\n",
    "\n",
    "    project.add_step(TextDataAnalysis(), [\n",
    "                     CheckResultExists(\"number_of_classes\"),\n",
    "                     CheckResultExists(\"class_names\"),\n",
    "                     CheckResultExists(\"number_of_reviews_in_each_class\")])\n",
    "    # get calculated number of classes in the previous step\n",
    "\n",
    "    NUM_CLASSES = project.get_step(0).get_latest_run()[\"number_of_classes\"]\n",
    "    METRICS = [Accuracy(num_classes=NUM_CLASSES), Precision(num_classes=NUM_CLASSES), Recall(\n",
    "        num_classes=NUM_CLASSES), F1(num_classes=NUM_CLASSES)]  # define metrics\n",
    "    project.register_metrics(METRICS)  # register metrics in the project\n",
    "\n",
    "    project.run_all()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage you should see, that the first step was skipped, because we already have executed it.\n",
    "\n",
    "We prepared one baseline for you in `models/simple_baseline.py`. Add it to the project and run it. You can do it by adding following lines to the main() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simple_baseline import HeuristicBaseline\n",
    "\n",
    "baseline = HeuristicBaseline()\n",
    "project.add_step(\n",
    "    step=EvaluateBaseline(baseline),\n",
    "    checks=[CheckScoreExists(metric=METRICS[i])\n",
    "            for i in range(len(METRICS))],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "\n",
    "<summary>Correct main()</summary>\n",
    "\n",
    "```py\n",
    "def main():\n",
    "    data = YelpReviews()\n",
    "    project = ArtProject(\"yelpreviews\", data)\n",
    "\n",
    "    project.add_step(TextDataAnalysis(), [\n",
    "                     CheckResultExists(\"number_of_classes\"),\n",
    "                     CheckResultExists(\"class_names\"),\n",
    "                     CheckResultExists(\"number_of_reviews_in_each_class\")])\n",
    "    # get calculated number of classes in the previous step\n",
    "\n",
    "    NUM_CLASSES = 5\n",
    "    METRICS = [\n",
    "        Accuracy(num_classes=NUM_CLASSES, average='macro', task='multiclass'),\n",
    "        Precision(num_classes=NUM_CLASSES, average='macro', task='multiclass'),\n",
    "        Recall(num_classes=NUM_CLASSES, average='macro', task='multiclass')\n",
    "    ]  # define metrics\n",
    "    project.register_metrics(METRICS)  # register metrics in the project\n",
    "\n",
    "    baseline = HeuristicBaseline()\n",
    "    project.add_step(\n",
    "        step=EvaluateBaseline(baseline),\n",
    "        checks=[CheckScoreExists(metric=METRICS[i])\n",
    "                for i in range(len(METRICS))],\n",
    "    )\n",
    "\n",
    "    project.run_all()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct output should look like this:\n",
    "```\n",
    "Steps status:\n",
    "\n",
    "data_analysis_Data analysis: Skipped. Results:\n",
    "        number_of_classes: 5\n",
    "        class_names: ['0', '1', '2', '3', '4']\n",
    "        number_of_reviews_in_each_class: {'4': 189, '1': 240, '3': 174, '0': 189, '2': 208}\n",
    "\n",
    "        \n",
    "HeuristicBaseline_2_Evaluate Baseline: Completed. Results:\n",
    "        MulticlassAccuracy-HeuristicBaseline-validate-Evaluate Baseline: 0.30702152848243713\n",
    "        MulticlassPrecision-HeuristicBaseline-validate-Evaluate Baseline: 0.3316725790500641\n",
    "        MulticlassRecall-HeuristicBaseline-validate-Evaluate Baseline: 0.30702152848243713\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the proper model...\n",
    "\n",
    "... but first in the experimental mode:\n",
    "* Check loss on init with frozen backbone - cls head only\n",
    "* Overfitting one batch with frozen backbone\n",
    "* Overfitting entire dataset with frozen backbone\n",
    "* Check loss on init ((???)) with unfrozen backbone\n",
    "* Overfitting one batch with unfrozen backbone\n",
    "* Overfitting entire dataset with unfrozen backbone\n",
    "* Training on entire dataset - first with frozen backbone, then with unfrozen backbone and reduced learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\polibuda\\inzynierka_utils\\art_template\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading model.safetensors: 100%|██████████| 436M/436M [00:10<00:00, 39.8MB/s] \n",
      "c:\\polibuda\\inzynierka_utils\\art_template\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dell\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert.embeddings.word_embeddings.weight',\n",
       " 'bert.embeddings.position_embeddings.weight',\n",
       " 'bert.embeddings.token_type_embeddings.weight',\n",
       " 'bert.embeddings.LayerNorm.weight',\n",
       " 'bert.embeddings.LayerNorm.bias']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param[0] for param in model.named_parameters()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
